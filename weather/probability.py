"""NOAA probability model — dynamic accuracy by horizon, season, and bucket width."""

import json
import math
import logging
from datetime import datetime, timezone
from pathlib import Path
from zoneinfo import ZoneInfo

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Calibration data loading (from calibration.json generated by weather.calibrate)
# ---------------------------------------------------------------------------

_calibration_cache: dict | None = None
_calibration_mtime: float = 0.0
_CALIBRATION_PATH = Path(__file__).parent / "calibration.json"


def _load_calibration() -> dict:
    """Load calibration data from calibration.json with mtime-based cache invalidation.

    Falls back to empty dict if file doesn't exist or is invalid,
    causing all lookups to use the hardcoded default tables.
    """
    global _calibration_cache, _calibration_mtime

    try:
        current_mtime = _CALIBRATION_PATH.stat().st_mtime
    except OSError:
        current_mtime = 0.0

    if _calibration_cache is not None and current_mtime == _calibration_mtime:
        return _calibration_cache

    if _CALIBRATION_PATH.exists():
        try:
            with open(_CALIBRATION_PATH) as f:
                _calibration_cache = json.load(f)
            _calibration_mtime = current_mtime
            logger.info("Loaded calibration data from %s (%d samples)",
                        _CALIBRATION_PATH,
                        _calibration_cache.get("metadata", {}).get("samples", 0))
            return _calibration_cache
        except (json.JSONDecodeError, IOError) as exc:
            logger.warning("Failed to load calibration data: %s — using defaults", exc)

    _calibration_cache = {}
    _calibration_mtime = current_mtime
    return _calibration_cache

# NOAA forecast accuracy curve (days ahead → probability of being correct)
_HORIZON_ACCURACY = {
    0: 0.97,
    1: 0.95,
    2: 0.90,
    3: 0.85,
    4: 0.80,
    5: 0.75,
    6: 0.70,
    7: 0.65,
    8: 0.60,
    9: 0.55,
    10: 0.50,
}

# Standard deviation of NOAA forecast error (°F) by horizon
# Used for bucket probability estimation via normal CDF
_HORIZON_STDDEV = {
    0: 2.0,
    1: 2.6,
    2: 3.3,
    3: 3.9,
    4: 4.6,
    5: 5.2,
    6: 6.5,
    7: 7.9,
    8: 9.2,
    9: 10.5,
    10: 11.8,
}

# Seasonal sigma multiplier (month → factor)
# factor > 1.0 = month is MORE uncertain (multiply sigma up)
# factor < 1.0 = month is LESS uncertain (multiply sigma down)
# Winter forecasts are harder (storms, cold fronts), summer/fall more stable
_SEASONAL_FACTORS = {
    1: 1.02, 2: 1.20, 3: 1.08,   # Winter / early spring (hardest)
    4: 1.09, 5: 1.14, 6: 1.09,   # Spring / early summer
    7: 1.08, 8: 1.01, 9: 0.97,   # Summer / early fall
    10: 0.79, 11: 0.74, 12: 0.80,  # Fall / winter (easiest)
}


def _normal_cdf(x: float) -> float:
    """Standard normal CDF using math.erf (stdlib, zero dependencies)."""
    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))


def get_horizon_days(forecast_date: str) -> int:
    """Number of days between now (UTC) and the forecast date."""
    try:
        target = datetime.strptime(forecast_date, "%Y-%m-%d").date()
    except ValueError:
        return 999  # Invalid date — will be filtered by max_days_ahead
    today = datetime.now(timezone.utc).date()
    return max(0, (target - today).days)


def get_noaa_probability(forecast_date: str, apply_seasonal: bool = True) -> float:
    """Dynamic NOAA probability based on forecast horizon and season.

    Returns a probability in [0.0, 1.0] representing how likely the NOAA
    point forecast is to be correct for the given date.
    """
    days_ahead = get_horizon_days(forecast_date)
    # Clamp to our table range, linearly interpolate beyond
    if days_ahead <= 10:
        base_prob = _HORIZON_ACCURACY.get(days_ahead, 0.50)
    else:
        base_prob = max(0.40, 0.50 - 0.02 * (days_ahead - 10))

    if apply_seasonal:
        try:
            month = int(forecast_date.split("-")[1])
        except (IndexError, ValueError):
            month = datetime.now(timezone.utc).month
        factor = _SEASONAL_FACTORS.get(month, 1.0)
        # factor > 1.0 = harder month = lower accuracy
        base_prob /= factor

    return round(max(0.01, min(base_prob, 0.99)), 4)


def _get_stddev(forecast_date: str, location: str = "") -> float:
    """Forecast error standard deviation for the given horizon.

    Lookup chain: location_sigma → global_sigma → hardcoded _HORIZON_STDDEV.
    """
    days_ahead = get_horizon_days(forecast_date)
    cal = _load_calibration()
    horizon_key = str(days_ahead)

    # 1. Location-specific sigma
    if location and cal:
        loc_sigma = cal.get("location_sigma", {}).get(location, {})
        if horizon_key in loc_sigma:
            return float(loc_sigma[horizon_key])

    # 2. Global calibrated sigma
    if cal:
        global_sigma = cal.get("global_sigma", {})
        if horizon_key in global_sigma:
            return float(global_sigma[horizon_key])

    # 3. Hardcoded fallback
    if days_ahead <= 10:
        return _HORIZON_STDDEV.get(days_ahead, 11.8)
    return min(18.0, 11.8 + 0.7 * (days_ahead - 10))


def _get_seasonal_factor(month: int, location: str = "") -> float:
    """Seasonal adjustment factor for the given month.

    Lookup chain: location_seasonal → global seasonal_factors → hardcoded _SEASONAL_FACTORS.
    """
    cal = _load_calibration()
    month_key = str(month)

    # 1. Location-specific seasonal
    if location and cal:
        loc_seasonal = cal.get("location_seasonal", {}).get(location, {})
        if month_key in loc_seasonal:
            return float(loc_seasonal[month_key])

    # 2. Global calibrated seasonal
    if cal:
        global_seasonal = cal.get("seasonal_factors", {})
        if month_key in global_seasonal:
            return float(global_seasonal[month_key])

    # 3. Hardcoded fallback
    return _SEASONAL_FACTORS.get(month, 1.0)


# ---------------------------------------------------------------------------
# Weather-based sigma adjustment (Phase 3)
# ---------------------------------------------------------------------------

def _weather_sigma_multiplier(weather_data: dict, metric: str = "high") -> float:
    """Compute a sigma multiplier based on auxiliary weather conditions.

    Higher cloud cover, wind, or precipitation increase forecast uncertainty.

    Args:
        weather_data: Dict with keys like ``cloud_cover_max``, ``wind_speed_max``,
            ``wind_gusts_max``, ``precip_sum``.
        metric: ``"high"`` or ``"low"``.

    Returns:
        Multiplier >= 1.0 (1.0 means no adjustment).
    """
    multiplier = 1.0

    # Cloud cover > 80% increases uncertainty for highs
    cloud_cover = weather_data.get("cloud_cover_max")
    if cloud_cover is not None and cloud_cover > 80 and metric == "high":
        multiplier += 0.10

    # High winds increase uncertainty
    wind_speed = weather_data.get("wind_speed_max")
    wind_gusts = weather_data.get("wind_gusts_max")
    effective_wind = max(wind_speed or 0, wind_gusts or 0)
    if effective_wind > 40:  # km/h
        multiplier += 0.08

    # Precipitation increases uncertainty for highs
    precip = weather_data.get("precip_sum")
    if precip is not None and precip > 10 and metric == "high":
        multiplier += 0.12

    return multiplier


def estimate_bucket_probability(
    forecast_temp: float,
    bucket_low: int,
    bucket_high: int,
    forecast_date: str,
    apply_seasonal: bool = True,
    location: str = "",
    weather_data: dict | None = None,
    metric: str = "high",
) -> float:
    """Estimate P(actual temperature ∈ [bucket_low, bucket_high]).

    Uses a normal distribution centered on the NOAA forecast temperature,
    with standard deviation based on the forecast horizon.

    Sentinel values: -999 = open below, 999 = open above.

    Args:
        forecast_temp: Forecast temperature (ensemble or NOAA).
        bucket_low: Lower bound of bucket (-999 = open below).
        bucket_high: Upper bound of bucket (999 = open above).
        forecast_date: Date string ``"YYYY-MM-DD"``.
        apply_seasonal: Whether to apply seasonal adjustments.
        location: Canonical location key for calibrated sigma lookup.
        weather_data: Optional auxiliary weather data for sigma adjustment.
        metric: ``"high"`` or ``"low"`` — which extreme this event tracks.
    """
    sigma = _get_stddev(forecast_date, location=location)
    if apply_seasonal:
        try:
            month = int(forecast_date.split("-")[1])
        except (IndexError, ValueError):
            month = datetime.now(timezone.utc).month
        factor = _get_seasonal_factor(month, location=location)
        # factor > 1.0 → harder month → widen sigma; < 1.0 → easier → narrow
        sigma *= factor

    # Weather-based sigma adjustment
    if weather_data:
        sigma *= _weather_sigma_multiplier(weather_data, metric)

    # Guard against zero sigma
    if sigma <= 0:
        sigma = 0.01

    # CDF bounds
    if bucket_low <= -900:
        cdf_low = 0.0
    else:
        cdf_low = _normal_cdf((bucket_low - 0.5 - forecast_temp) / sigma)

    if bucket_high >= 900:
        cdf_high = 1.0
    else:
        cdf_high = _normal_cdf((bucket_high + 0.5 - forecast_temp) / sigma)

    prob = max(0.0, cdf_high - cdf_low)
    return round(prob, 4)


# ---------------------------------------------------------------------------
# Observation-adjusted probability (METAR integration)
# ---------------------------------------------------------------------------

def _intraday_sigma(latest_obs_time: str, metric: str, tz_name: str = "America/New_York") -> float:
    """Dynamic sigma based on how late in the **local** day we have observations.

    The later in the day, the less the temperature can change, so sigma shrinks.

    Args:
        latest_obs_time: ISO 8601 timestamp (e.g. ``"2025-03-15T18:00:00Z"``).
        metric: ``"high"`` or ``"low"``.
        tz_name: IANA timezone name (DST-aware).

    Sigma schedule (local time, for "high"):
        Before 10:00 local → 3.0°F  (morning, peak not yet reached)
        10:00–14:00 local  → 2.0°F  (midday, approaching peak)
        14:00–17:00 local  → 1.0°F  (afternoon, near peak)
        After 17:00 local  → 0.5°F  (evening, peak almost certainly passed)

    For "low", the logic is inverted (lows happen in early morning local time).
    """
    try:
        utc_dt = datetime.fromisoformat(latest_obs_time.replace("Z", "+00:00"))
        local_dt = utc_dt.astimezone(ZoneInfo(tz_name))
        local_hour = local_dt.hour
    except (ValueError, IndexError, KeyError):
        return 3.0  # Default: high uncertainty

    if metric == "high":
        if local_hour < 10:
            return 3.0
        elif local_hour < 14:
            return 2.0
        elif local_hour < 17:
            return 1.0
        return 0.5
    else:
        # For lows: minimum typically occurs in early morning (04-08 local)
        if local_hour < 6:
            return 3.0
        elif local_hour < 10:
            return 2.0
        elif local_hour < 14:
            return 1.0
        return 0.5


def constrained_forecast(
    obs_extreme: float,
    model_forecast: float,
    metric: str,
) -> float:
    """Constrain the model forecast using the observed running extreme.

    For "high": the actual daily high cannot be lower than the running
    observed high (temperature may still go up, but can't go down).

    For "low": the actual daily low cannot be higher than the running
    observed low (temperature may still drop, but the low can't increase).
    """
    if metric == "high":
        return max(obs_extreme, model_forecast)
    else:
        return min(obs_extreme, model_forecast)


def _tz_from_lon(lon: float) -> str:
    """Approximate IANA timezone from longitude (US stations only)."""
    if lon > -85:
        return "America/New_York"
    elif lon > -100:
        return "America/Chicago"
    elif lon > -115:
        return "America/Denver"
    return "America/Los_Angeles"


def estimate_bucket_probability_with_obs(
    forecast_temp: float,
    bucket_low: int,
    bucket_high: int,
    forecast_date: str,
    obs_data: dict | None = None,
    metric: str = "high",
    apply_seasonal: bool = True,
    station_lon: float = -74.0,
    station_tz: str = "",
    location: str = "",
    weather_data: dict | None = None,
) -> float:
    """Estimate bucket probability with observation-based uncertainty reduction.

    When ``obs_data`` is provided (from METAR), the forecast is constrained
    by the running observed extreme and sigma is reduced based on the time
    of the latest observation.

    Args:
        forecast_temp: Ensemble forecast temperature.
        bucket_low: Lower bound of the bucket (sentinel -999 = open below).
        bucket_high: Upper bound of the bucket (sentinel 999 = open above).
        forecast_date: Date string ``"YYYY-MM-DD"``.
        obs_data: Optional dict with keys ``obs_high``, ``obs_low``,
            ``latest_obs_time``, ``obs_count``.
        metric: ``"high"`` or ``"low"`` — which extreme this event tracks.
        apply_seasonal: Whether to apply seasonal adjustments.
        station_lon: Longitude of the station (for timezone-aware sigma).
        station_tz: IANA timezone name.
        location: Canonical location key for calibrated sigma lookup.
        weather_data: Optional auxiliary weather data for sigma adjustment.

    Returns:
        Probability in [0.0, 1.0].
    """
    if not obs_data or obs_data.get("obs_count", 0) == 0:
        return estimate_bucket_probability(
            forecast_temp, bucket_low, bucket_high,
            forecast_date, apply_seasonal=apply_seasonal,
            location=location, weather_data=weather_data,
        )

    latest_obs_time = obs_data.get("latest_obs_time", "")
    obs_key = f"obs_{metric}"
    obs_extreme = obs_data.get(obs_key)

    if obs_extreme is None:
        return estimate_bucket_probability(
            forecast_temp, bucket_low, bucket_high,
            forecast_date, apply_seasonal=apply_seasonal,
            location=location, weather_data=weather_data,
        )

    # Constrain forecast by observed extreme
    effective_temp = constrained_forecast(obs_extreme, forecast_temp, metric)

    # Use intraday sigma (tighter than horizon-based sigma on resolution day)
    tz_name = station_tz or _tz_from_lon(station_lon)
    sigma = _intraday_sigma(latest_obs_time, metric, tz_name=tz_name)

    if apply_seasonal:
        try:
            month = int(forecast_date.split("-")[1])
        except (IndexError, ValueError):
            month = datetime.now(timezone.utc).month
        factor = _get_seasonal_factor(month, location=location)
        sigma *= factor

    # Weather-based sigma adjustment
    if weather_data:
        sigma *= _weather_sigma_multiplier(weather_data, metric)

    # Guard against zero sigma
    if sigma <= 0:
        sigma = 0.01

    # CDF bounds
    if bucket_low <= -900:
        cdf_low = 0.0
    else:
        cdf_low = _normal_cdf((bucket_low - 0.5 - effective_temp) / sigma)

    if bucket_high >= 900:
        cdf_high = 1.0
    else:
        cdf_high = _normal_cdf((bucket_high + 0.5 - effective_temp) / sigma)

    prob = max(0.0, cdf_high - cdf_low)
    return round(prob, 4)
