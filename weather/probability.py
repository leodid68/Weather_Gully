"""NOAA probability model — dynamic accuracy by horizon, season, and bucket width."""

import json
import math
import logging
from datetime import datetime, timezone
from pathlib import Path
from zoneinfo import ZoneInfo

from .ensemble import EnsembleResult

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Calibration data loading (from calibration.json generated by weather.calibrate)
# ---------------------------------------------------------------------------

_calibration_cache: dict | None = None
_calibration_mtime: float = 0.0
_CALIBRATION_PATH = Path(__file__).parent / "calibration.json"


def _load_calibration() -> dict:
    """Load calibration data from calibration.json with mtime-based cache invalidation.

    Falls back to empty dict if file doesn't exist or is invalid,
    causing all lookups to use the hardcoded default tables.
    """
    global _calibration_cache, _calibration_mtime

    try:
        current_mtime = _CALIBRATION_PATH.stat().st_mtime
    except OSError:
        current_mtime = 0.0

    if _calibration_cache is not None and current_mtime == _calibration_mtime:
        return _calibration_cache

    if _CALIBRATION_PATH.exists():
        try:
            with open(_CALIBRATION_PATH) as f:
                _calibration_cache = json.load(f)
            _calibration_mtime = current_mtime
            logger.info("Loaded calibration data from %s (%d samples)",
                        _CALIBRATION_PATH,
                        _calibration_cache.get("metadata", {}).get("samples", 0))
            return _calibration_cache
        except (json.JSONDecodeError, IOError) as exc:
            logger.warning("Failed to load calibration data: %s — using defaults", exc)

    _calibration_cache = {}
    _calibration_mtime = current_mtime
    return _calibration_cache

# NOAA forecast accuracy curve (days ahead → probability of being correct)
_HORIZON_ACCURACY = {
    0: 0.97,
    1: 0.95,
    2: 0.90,
    3: 0.85,
    4: 0.80,
    5: 0.75,
    6: 0.70,
    7: 0.65,
    8: 0.60,
    9: 0.55,
    10: 0.50,
}

# Standard deviation of NOAA forecast error (°F) by horizon
# Used for bucket probability estimation via normal CDF
_HORIZON_STDDEV = {
    0: 2.0,
    1: 2.6,
    2: 3.3,
    3: 3.9,
    4: 4.6,
    5: 5.2,
    6: 6.5,
    7: 7.9,
    8: 9.2,
    9: 10.5,
    10: 11.8,
}

# Seasonal sigma multiplier (month → factor)
# factor > 1.0 = month is MORE uncertain (multiply sigma up)
# factor < 1.0 = month is LESS uncertain (multiply sigma down)
# Winter forecasts are harder (storms, cold fronts), summer/fall more stable
_SEASONAL_FACTORS = {
    1: 1.02, 2: 1.20, 3: 1.08,   # Winter / early spring (hardest)
    4: 1.09, 5: 1.14, 6: 1.09,   # Spring / early summer
    7: 1.08, 8: 1.01, 9: 0.97,   # Summer / early fall
    10: 0.79, 11: 0.74, 12: 0.80,  # Fall / winter (easiest)
}


def _normal_cdf(x: float) -> float:
    """Standard normal CDF using math.erf (stdlib, zero dependencies)."""
    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))


def _regularized_incomplete_beta(x: float, a: float, b: float, max_iter: int = 200) -> float:
    """Regularized incomplete beta function I_x(a, b) via continued fraction.

    Uses the Lentz algorithm for the continued fraction representation.
    """
    if x <= 0:
        return 0.0
    if x >= 1:
        return 1.0

    # Guard: a and b must be positive for lgamma / beta function
    if a <= 0 or b <= 0:
        logger.warning("_regularized_incomplete_beta: invalid a=%.4g b=%.4g, returning 0.0", a, b)
        return 0.0

    # Clamp x away from exact 0/1 to avoid log(0) in prefactor
    x = max(1e-15, min(1 - 1e-15, x))

    # Use the symmetry relation if x > (a+1)/(a+b+2)
    if x > (a + 1) / (a + b + 2):
        return 1.0 - _regularized_incomplete_beta(1.0 - x, b, a, max_iter)

    # Log of the prefactor: x^a * (1-x)^b / (a * B(a,b))
    lbeta = math.lgamma(a) + math.lgamma(b) - math.lgamma(a + b)
    front = math.exp(a * math.log(x) + b * math.log(1.0 - x) - lbeta) / a

    # Lentz's continued fraction
    f = 1.0
    c = 1.0
    d = 1.0 - (a + b) * x / (a + 1.0)
    if abs(d) < 1e-30:
        d = 1e-30
    d = 1.0 / d
    f = d

    for m in range(1, max_iter + 1):
        # Even step
        numerator = m * (b - m) * x / ((a + 2*m - 1) * (a + 2*m))
        d = 1.0 + numerator * d
        if abs(d) < 1e-30:
            d = 1e-30
        d = 1.0 / d
        c = 1.0 + numerator / c
        if abs(c) < 1e-30:
            c = 1e-30
        f *= c * d

        # Odd step
        numerator = -(a + m) * (a + b + m) * x / ((a + 2*m) * (a + 2*m + 1))
        d = 1.0 + numerator * d
        if abs(d) < 1e-30:
            d = 1e-30
        d = 1.0 / d
        c = 1.0 + numerator / c
        if abs(c) < 1e-30:
            c = 1e-30
        delta = c * d
        f *= delta

        if abs(delta - 1.0) < 1e-10:
            break
    else:
        logger.warning("_regularized_incomplete_beta: continued fraction did not converge after %d iterations (x=%.4g, a=%.4g, b=%.4g)", max_iter, x, a, b)

    return front * f


def _student_t_cdf(x: float, df: float) -> float:
    """CDF of standard Student's t-distribution.

    Uses the regularized incomplete beta function.
    For df > 100, falls back to normal CDF (negligible difference).
    """
    # Guard: invalid inputs
    if math.isnan(x) or df <= 0:
        logger.warning("Invalid student_t_cdf input: x=%s df=%s — returning 0.5", x, df)
        return 0.5
    if math.isinf(x):
        return 1.0 if x > 0 else 0.0

    if df > 100:
        return _normal_cdf(x)
    t2 = x * x
    z = df / (df + t2)
    ibeta = _regularized_incomplete_beta(z, df / 2.0, 0.5)
    if x >= 0:
        return 1.0 - 0.5 * ibeta
    else:
        return 0.5 * ibeta


def get_horizon_days(forecast_date: str) -> int:
    """Number of days between now (UTC) and the forecast date."""
    try:
        target = datetime.strptime(forecast_date, "%Y-%m-%d").date()
    except ValueError:
        return 999  # Invalid date — will be filtered by max_days_ahead
    today = datetime.now(timezone.utc).date()
    return max(0, (target - today).days)


def get_noaa_probability(forecast_date: str, apply_seasonal: bool = True) -> float:
    """Dynamic NOAA probability based on forecast horizon and season.

    Returns a probability in [0.0, 1.0] representing how likely the NOAA
    point forecast is to be correct for the given date.
    """
    days_ahead = get_horizon_days(forecast_date)
    # Clamp to our table range, linearly interpolate beyond
    if days_ahead <= 10:
        base_prob = _HORIZON_ACCURACY.get(days_ahead, 0.50)
    else:
        base_prob = max(0.40, 0.50 - 0.02 * (days_ahead - 10))

    if apply_seasonal:
        try:
            month = int(forecast_date.split("-")[1])
        except (IndexError, ValueError):
            month = datetime.now(timezone.utc).month
        factor = _SEASONAL_FACTORS.get(month, 1.0)
        # factor > 1.0 = harder month = lower accuracy
        base_prob /= factor

    return round(max(0.01, min(base_prob, 0.99)), 4)


def _get_stddev(forecast_date: str, location: str = "", horizon_override: int | None = None) -> float:
    """Forecast error standard deviation for the given horizon.

    Lookup chain: location_sigma → global_sigma → hardcoded _HORIZON_STDDEV.

    Args:
        horizon_override: If provided, use this horizon instead of computing
            from ``forecast_date`` vs today.  Essential for backtesting where
            ``forecast_date`` is in the past.
    """
    days_ahead = horizon_override if horizon_override is not None else get_horizon_days(forecast_date)
    cal = _load_calibration()
    horizon_key = str(days_ahead)

    # 1. Location-specific sigma
    if location and cal:
        loc_sigma = cal.get("location_sigma", {}).get(location, {})
        if horizon_key in loc_sigma:
            return float(loc_sigma[horizon_key])

    # 2. Global calibrated sigma
    if cal:
        global_sigma = cal.get("global_sigma", {})
        if horizon_key in global_sigma:
            return float(global_sigma[horizon_key])

    # 3. Hardcoded fallback
    if days_ahead <= 10:
        return _HORIZON_STDDEV.get(days_ahead, 11.8)
    return min(18.0, 11.8 + 0.7 * (days_ahead - 10))


def _get_seasonal_factor(month: int, location: str = "") -> float:
    """Seasonal adjustment factor for the given month.

    Lookup chain: location_seasonal → global seasonal_factors → hardcoded _SEASONAL_FACTORS.
    """
    cal = _load_calibration()
    month_key = str(month)

    # 1. Location-specific seasonal
    if location and cal:
        loc_seasonal = cal.get("location_seasonal", {}).get(location, {})
        if month_key in loc_seasonal:
            return float(loc_seasonal[month_key])

    # 2. Global calibrated seasonal
    if cal:
        global_seasonal = cal.get("seasonal_factors", {})
        if month_key in global_seasonal:
            return float(global_seasonal[month_key])

    # 3. Hardcoded fallback
    return _SEASONAL_FACTORS.get(month, 1.0)


# ---------------------------------------------------------------------------
# Adaptive sigma (ensemble + model spread + EMA error)
# ---------------------------------------------------------------------------

# Adaptive sigma conversion factors (NWP literature defaults)
_UNDERDISPERSION_FACTOR = 1.3   # Ensemble spread is typically underdispersed
_SPREAD_TO_SIGMA = 0.7          # |GFS - ECMWF| to sigma conversion
_EMA_TO_SIGMA = 1.25            # MAE -> sigma for Gaussian (MAE ~ 0.8 sigma)


def _load_adaptive_factors() -> dict:
    """Load calibrated adaptive sigma factors from calibration.json.

    Looks for the ``"adaptive_sigma"`` key in the calibration data.
    Returns an empty dict if the key is not present or calibration
    data is unavailable.
    """
    cal = _load_calibration()
    return cal.get("adaptive_sigma", {})


def _load_platt_params() -> dict:
    """Load Platt scaling parameters from calibration.json.
    Returns dict with 'a' and 'b' keys, or empty dict if unavailable.
    """
    cal = _load_calibration()
    return cal.get("platt_scaling", {})


def platt_calibrate(prob: float) -> float:
    """Apply Platt scaling to a raw probability.
    Transforms: calibrated = sigmoid(a * logit(prob) + b)
    Falls back to identity if no calibration params available.
    Output bounded to [0.01, 0.99].
    """
    params = _load_platt_params()
    a = params.get("a", 1.0)
    b = params.get("b", 0.0)

    # Identity shortcut
    if a == 1.0 and b == 0.0:
        return max(0.01, min(0.99, prob))

    # Clamp input to avoid log(0)
    p = max(1e-6, min(1 - 1e-6, prob))
    logit_p = math.log(p / (1 - p))
    z = max(-500, min(500, a * logit_p + b))
    calibrated = 1.0 / (1.0 + math.exp(-z))

    return max(0.01, min(0.99, round(calibrated, 4)))


def compute_adaptive_sigma(
    ensemble_result: EnsembleResult | None,
    model_spread: float,
    ema_error: float | None,
    forecast_date: str,
    location: str = "",
) -> float:
    """Compute adaptive sigma from three independent uncertainty signals.

    Takes the maximum of ensemble stddev (underdispersion-corrected),
    model spread (GFS-vs-ECMWF), EMA of recent forecast errors, and
    a calibrated floor to avoid overconfidence.

    Args:
        ensemble_result: Ensemble statistics (may be ``None``).
        model_spread: Absolute difference between GFS and ECMWF forecasts.
        ema_error: Exponential moving average of recent forecast errors
            (``None`` or ``0`` to skip).
        forecast_date: ISO date string ``"YYYY-MM-DD"``.
        location: Canonical location key for calibrated lookups.

    Returns:
        Adaptive sigma (always > 0).
    """
    factors = _load_adaptive_factors()
    underdispersion_factor = factors.get("underdispersion_factor", _UNDERDISPERSION_FACTOR)
    spread_to_sigma_factor = factors.get("spread_to_sigma_factor", _SPREAD_TO_SIGMA)
    ema_to_sigma_factor = factors.get("ema_to_sigma_factor", _EMA_TO_SIGMA)

    # Signal 1: ensemble spread (underdispersion-corrected)
    sigma_ensemble = 0.0
    if ensemble_result is not None and ensemble_result.n_members >= 2:
        sigma_ensemble = ensemble_result.ensemble_stddev * underdispersion_factor

    # Signal 2: model spread (|GFS - ECMWF|)
    sigma_spread = model_spread * spread_to_sigma_factor

    # Signal 3: EMA of recent forecast errors
    sigma_ema = 0.0
    if ema_error is not None and ema_error > 0:
        sigma_ema = ema_error * ema_to_sigma_factor

    # Floor: calibrated horizon sigma * seasonal factor
    try:
        month = int(forecast_date.split("-")[1])
    except (IndexError, ValueError):
        month = datetime.now(timezone.utc).month
    sigma_floor = _get_stddev(forecast_date, location) * _get_seasonal_factor(month, location)

    result = max(sigma_ensemble, sigma_spread, sigma_ema, sigma_floor)

    logger.debug(
        "adaptive_sigma: ensemble=%.2f spread=%.2f ema=%.2f floor=%.2f -> %.2f",
        sigma_ensemble, sigma_spread, sigma_ema, sigma_floor, result,
    )

    return result


# ---------------------------------------------------------------------------
# Weather-based sigma adjustment (Phase 3)
# ---------------------------------------------------------------------------

def _weather_sigma_multiplier(weather_data: dict, metric: str = "high") -> float:
    """Compute a sigma multiplier based on auxiliary weather conditions.

    Higher cloud cover, wind, or precipitation increase forecast uncertainty.

    Args:
        weather_data: Dict with keys like ``cloud_cover_max``, ``wind_speed_max``,
            ``wind_gusts_max``, ``precip_sum``.
        metric: ``"high"`` or ``"low"``.

    Returns:
        Multiplier >= 1.0 (1.0 means no adjustment).
    """
    multiplier = 1.0

    # Cloud cover > 80% increases uncertainty for highs
    cloud_cover = weather_data.get("cloud_cover_max")
    if cloud_cover is not None and cloud_cover > 80 and metric == "high":
        multiplier += 0.10

    # High winds increase uncertainty
    wind_speed = weather_data.get("wind_speed_max")
    wind_gusts = weather_data.get("wind_gusts_max")
    effective_wind = max(wind_speed or 0, wind_gusts or 0)
    if effective_wind > 40:  # km/h
        multiplier += 0.08

    # Precipitation increases uncertainty for highs
    precip = weather_data.get("precip_sum")
    if precip is not None and precip > 10 and metric == "high":
        multiplier += 0.12

    return multiplier


def estimate_bucket_probability(
    forecast_temp: float,
    bucket_low: int,
    bucket_high: int,
    forecast_date: str,
    apply_seasonal: bool = True,
    location: str = "",
    weather_data: dict | None = None,
    metric: str = "high",
    sigma_override: float | None = None,
    horizon_override: int | None = None,
) -> float:
    """Estimate P(actual temperature ∈ [bucket_low, bucket_high]).

    Uses a normal distribution centered on the NOAA forecast temperature,
    with standard deviation based on the forecast horizon.

    Sentinel values: -999 = open below, 999 = open above.

    Args:
        forecast_temp: Forecast temperature (ensemble or NOAA).
        bucket_low: Lower bound of bucket (-999 = open below).
        bucket_high: Upper bound of bucket (999 = open above).
        forecast_date: Date string ``"YYYY-MM-DD"``.
        apply_seasonal: Whether to apply seasonal adjustments.
        location: Canonical location key for calibrated sigma lookup.
        weather_data: Optional auxiliary weather data for sigma adjustment.
        metric: ``"high"`` or ``"low"`` — which extreme this event tracks.
    """
    if sigma_override is not None:
        sigma = sigma_override
    else:
        sigma = _get_stddev(forecast_date, location=location, horizon_override=horizon_override)
        if apply_seasonal:
            try:
                month = int(forecast_date.split("-")[1])
            except (IndexError, ValueError):
                month = datetime.now(timezone.utc).month
            factor = _get_seasonal_factor(month, location=location)
            sigma *= factor
        if weather_data:
            sigma *= _weather_sigma_multiplier(weather_data, metric)

    # Guard against zero sigma
    if sigma <= 0:
        sigma = 0.01
    sigma = min(sigma, 50.0)

    # Determine CDF function based on calibration distribution
    cal = _load_calibration()
    dist = cal.get("distribution", "normal") if cal else "normal"
    if dist == "student_t":
        t_df = cal.get("student_t_df", 30)
        cdf_fn = lambda z: _student_t_cdf(z, t_df)
    else:
        cdf_fn = _normal_cdf

    # CDF bounds
    if bucket_low <= -900:
        cdf_low = 0.0
    else:
        cdf_low = cdf_fn((bucket_low - 0.5 - forecast_temp) / sigma)

    if bucket_high >= 900:
        cdf_high = 1.0
    else:
        cdf_high = cdf_fn((bucket_high + 0.5 - forecast_temp) / sigma)

    prob = max(0.0, min(1.0, cdf_high - cdf_low))
    return round(prob, 4)


# ---------------------------------------------------------------------------
# Observation-adjusted probability (METAR integration)
# ---------------------------------------------------------------------------

def _intraday_sigma(latest_obs_time: str, metric: str, tz_name: str = "America/New_York") -> float:
    """Dynamic sigma based on how late in the **local** day we have observations.

    The later in the day, the less the temperature can change, so sigma shrinks.

    Args:
        latest_obs_time: ISO 8601 timestamp (e.g. ``"2025-03-15T18:00:00Z"``).
        metric: ``"high"`` or ``"low"``.
        tz_name: IANA timezone name (DST-aware).

    Sigma schedule (local time, for "high"):
        Before 10:00 local → 3.0°F  (morning, peak not yet reached)
        10:00–14:00 local  → 2.0°F  (midday, approaching peak)
        14:00–17:00 local  → 1.0°F  (afternoon, near peak)
        After 17:00 local  → 0.5°F  (evening, peak almost certainly passed)

    For "low", the logic is inverted (lows happen in early morning local time).
    """
    try:
        utc_dt = datetime.fromisoformat(latest_obs_time.replace("Z", "+00:00"))
        local_dt = utc_dt.astimezone(ZoneInfo(tz_name))
        local_hour = local_dt.hour
    except (ValueError, IndexError, KeyError):
        return 3.0  # Default: high uncertainty

    if metric == "high":
        if local_hour < 10:
            return 3.0
        elif local_hour < 14:
            return 2.0
        elif local_hour < 17:
            return 1.0
        return 0.5
    else:
        # For lows: minimum typically occurs in early morning (04-08 local)
        if local_hour < 6:
            return 3.0
        elif local_hour < 10:
            return 2.0
        elif local_hour < 14:
            return 1.0
        return 0.5


def constrained_forecast(
    obs_extreme: float,
    model_forecast: float,
    metric: str,
) -> float:
    """Constrain the model forecast using the observed running extreme.

    For "high": the actual daily high cannot be lower than the running
    observed high (temperature may still go up, but can't go down).

    For "low": the actual daily low cannot be higher than the running
    observed low (temperature may still drop, but the low can't increase).
    """
    if metric == "high":
        return max(obs_extreme, model_forecast)
    else:
        return min(obs_extreme, model_forecast)


def _tz_from_lon(lon: float) -> str:
    """Approximate IANA timezone from longitude (US stations only)."""
    if lon > -85:
        return "America/New_York"
    elif lon > -100:
        return "America/Chicago"
    elif lon > -115:
        return "America/Denver"
    return "America/Los_Angeles"


def estimate_bucket_probability_with_obs(
    forecast_temp: float,
    bucket_low: int,
    bucket_high: int,
    forecast_date: str,
    obs_data: dict | None = None,
    metric: str = "high",
    apply_seasonal: bool = True,
    station_lon: float = -74.0,
    station_tz: str = "",
    location: str = "",
    weather_data: dict | None = None,
    sigma_override: float | None = None,
) -> float:
    """Estimate bucket probability with observation-based uncertainty reduction.

    When ``obs_data`` is provided (from METAR), the forecast is constrained
    by the running observed extreme and sigma is reduced based on the time
    of the latest observation.

    Args:
        forecast_temp: Ensemble forecast temperature.
        bucket_low: Lower bound of the bucket (sentinel -999 = open below).
        bucket_high: Upper bound of the bucket (sentinel 999 = open above).
        forecast_date: Date string ``"YYYY-MM-DD"``.
        obs_data: Optional dict with keys ``obs_high``, ``obs_low``,
            ``latest_obs_time``, ``obs_count``.
        metric: ``"high"`` or ``"low"`` — which extreme this event tracks.
        apply_seasonal: Whether to apply seasonal adjustments.
        station_lon: Longitude of the station (for timezone-aware sigma).
        station_tz: IANA timezone name.
        location: Canonical location key for calibrated sigma lookup.
        weather_data: Optional auxiliary weather data for sigma adjustment.

    Returns:
        Probability in [0.0, 1.0].
    """
    if not obs_data or obs_data.get("obs_count", 0) == 0:
        return estimate_bucket_probability(
            forecast_temp, bucket_low, bucket_high,
            forecast_date, apply_seasonal=apply_seasonal,
            location=location, weather_data=weather_data,
            sigma_override=sigma_override,
        )

    latest_obs_time = obs_data.get("latest_obs_time", "")
    obs_key = f"obs_{metric}"
    obs_extreme = obs_data.get(obs_key)

    if obs_extreme is None:
        return estimate_bucket_probability(
            forecast_temp, bucket_low, bucket_high,
            forecast_date, apply_seasonal=apply_seasonal,
            location=location, weather_data=weather_data,
            sigma_override=sigma_override,
        )

    # Constrain forecast by observed extreme
    effective_temp = constrained_forecast(obs_extreme, forecast_temp, metric)

    # Use intraday sigma (tighter than horizon-based sigma on resolution day)
    tz_name = station_tz or _tz_from_lon(station_lon)
    intraday = _intraday_sigma(latest_obs_time, metric, tz_name=tz_name)

    if sigma_override is not None:
        # On resolution day with observations, use the tighter of the two
        sigma = min(sigma_override, intraday)
    else:
        sigma = intraday

        if apply_seasonal:
            try:
                month = int(forecast_date.split("-")[1])
            except (IndexError, ValueError):
                month = datetime.now(timezone.utc).month
            factor = _get_seasonal_factor(month, location=location)
            sigma *= factor

        # Weather-based sigma adjustment
        if weather_data:
            sigma *= _weather_sigma_multiplier(weather_data, metric)

    # Guard against zero sigma
    if sigma <= 0:
        sigma = 0.01
    sigma = min(sigma, 50.0)

    # Determine CDF function based on calibration distribution
    cal = _load_calibration()
    dist = cal.get("distribution", "normal") if cal else "normal"
    if dist == "student_t":
        t_df = cal.get("student_t_df", 30)
        cdf_fn = lambda z: _student_t_cdf(z, t_df)
    else:
        cdf_fn = _normal_cdf

    # CDF bounds
    if bucket_low <= -900:
        cdf_low = 0.0
    else:
        cdf_low = cdf_fn((bucket_low - 0.5 - effective_temp) / sigma)

    if bucket_high >= 900:
        cdf_high = 1.0
    else:
        cdf_high = cdf_fn((bucket_high + 0.5 - effective_temp) / sigma)

    prob = max(0.0, min(1.0, cdf_high - cdf_low))
    return round(prob, 4)
